{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionWrapper():\n",
    "    def __init__(self, model_params={'fit_intercept': False}):\n",
    "\n",
    "        self.model_name = \"linear_regression\"\n",
    "        self.search_type = 'grid'\n",
    "        self.param_grid = {'fit_intercept': [True, False]}\n",
    "        if model_params is None:\n",
    "            self.ModelClass = LinearRegression()\n",
    "        else:\n",
    "            self.ModelClass = LinearRegression(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY</th>\n",
       "      <th>RPI</th>\n",
       "      <th>S&amp;P: indust</th>\n",
       "      <th>HOUSTW</th>\n",
       "      <th>EXJPUSx</th>\n",
       "      <th>WPSID62</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-08-31</th>\n",
       "      <td>0.020416</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>6.063785</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.008375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-09-30</th>\n",
       "      <td>-0.010803</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.033748</td>\n",
       "      <td>6.113682</td>\n",
       "      <td>-0.033091</td>\n",
       "      <td>0.027151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-31</th>\n",
       "      <td>0.052144</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.011946</td>\n",
       "      <td>6.317165</td>\n",
       "      <td>-0.002906</td>\n",
       "      <td>-0.002173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-11-30</th>\n",
       "      <td>0.010862</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.011946</td>\n",
       "      <td>6.317165</td>\n",
       "      <td>-0.002906</td>\n",
       "      <td>-0.002173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-12-31</th>\n",
       "      <td>0.048997</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.031326</td>\n",
       "      <td>6.253829</td>\n",
       "      <td>-0.013278</td>\n",
       "      <td>0.032111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SPY       RPI  S&P: indust    HOUSTW   EXJPUSx   WPSID62\n",
       "date                                                                     \n",
       "2003-08-31  0.020416  0.001636     0.001452  6.063785 -0.000282 -0.008375\n",
       "2003-09-30 -0.010803  0.001476     0.033748  6.113682 -0.033091  0.027151\n",
       "2003-10-31  0.052144  0.005737     0.011946  6.317165 -0.002906 -0.002173\n",
       "2003-11-30  0.010862  0.005737     0.011946  6.317165 -0.002906 -0.002173\n",
       "2003-12-31  0.048997  0.000350     0.031326  6.253829 -0.013278  0.032111"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_data.csv')\n",
    "train_df.set_index(\"date\", inplace=True)\n",
    "\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"SPY\"\n",
    "k = 3\n",
    "model_wrapper = LinearRegressionWrapper(model_params={'fit_intercept': False})\n",
    "\n",
    "model = model_wrapper.ModelClass\n",
    "size_of_fold = len(train_df) // k\n",
    "features = train_df.columns.difference([target])\n",
    "score = make_scorer(mean_squared_error)\n",
    "\n",
    "# split the data into k folds\n",
    "folds = []\n",
    "for i in range(k):\n",
    "    start = i * size_of_fold\n",
    "    end = (i + 1) * size_of_fold\n",
    "    if i == k - 1:\n",
    "        end = len(train_df)\n",
    "    fold = train_df.iloc[start:end]\n",
    "    folds.append(fold)\n",
    "\n",
    "# make k combinations 2 by 2 of the folds where order does not matter\n",
    "combinations = []\n",
    "for i in range(k):\n",
    "    for j in range(i + 1, k):\n",
    "        combinations.append((folds[i], folds[j]))\n",
    "\n",
    "# # for each combination, train the model on the first fold and test on the second fold\n",
    "# pbar = tqdm(total=len(combinations) * len(features))\n",
    "# for feature in features:\n",
    "#     print(f\"Feature: {feature}\")\n",
    "#     for i, (train_fold, test_fold) in enumerate(combinations):\n",
    "#         pbar.set_description(f\"Feature: {feature} - Fold {i + 1}\")\n",
    "        \n",
    "#         train_model_fit = model.fit(train_fold.drop(columns=\"target\"), train_fold[\"target\"])\n",
    "\n",
    "\n",
    "#         # compute the error\n",
    "#         # print the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = next(iter(features))\n",
    "i, (train_fold, test_fold) = next(iter(enumerate(combinations)))\n",
    "\n",
    "# Prepare the features and target for training\n",
    "X_train = train_fold.drop(columns=target)\n",
    "X_train_without_feature = train_fold.drop(columns=[target, feature])\n",
    "y_train = train_fold[target]\n",
    "\n",
    "# Prepare the features for testing\n",
    "X_test = test_fold.drop(columns=target)\n",
    "# X_test_without_feature = test_fold.drop(columns=[target, feature])\n",
    "y_test = test_fold[target]\n",
    "\n",
    "model_with_feature = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = next(iter(features))\n",
    "all_generalization_errors_with_feature = []\n",
    "all_generalization_errors_without_feature = []\n",
    "for i, (train_fold, test_fold) in enumerate(combinations):\n",
    "\n",
    "    model1 = deepcopy(model)\n",
    "    model2 = deepcopy(model)\n",
    "\n",
    "    # Prepare the features and target for training\n",
    "    X_train = train_fold.drop(columns=target)\n",
    "    X_train_without_feature = train_fold.drop(columns=[target, feature])\n",
    "    y_train = train_fold[target]\n",
    "\n",
    "    # Prepare the features for testing\n",
    "    X_test = test_fold.drop(columns=target)\n",
    "    X_test_without_feature = test_fold.drop(columns=[target, feature])\n",
    "    y_test = test_fold[target]\n",
    "\n",
    "    # Fit the model\n",
    "    model_with_feature = model1.fit(X_train, y_train)\n",
    "    model_without_feature = model2.fit(X_train_without_feature, y_train)\n",
    "\n",
    "    # Predictions for the model\n",
    "    train_predictions_with_feature = model_with_feature.predict(X_train)\n",
    "    test_predictions_with_feature = model_with_feature.predict(X_test)\n",
    "    train_predictions_without_feature = model_without_feature.predict(X_train_without_feature)\n",
    "    test_predictions_without_feature = model_without_feature.predict(X_test_without_feature)\n",
    "\n",
    "    # Compute the error\n",
    "    train_error_with_feature = mean_squared_error(y_train, train_predictions_with_feature)\n",
    "    test_error_with_feature = mean_squared_error(y_test, test_predictions_with_feature)\n",
    "    train_error_without_feature = mean_squared_error(y_train, train_predictions_without_feature)\n",
    "    test_error_without_feature = mean_squared_error(y_test, test_predictions_without_feature)\n",
    "\n",
    "    # Compute generalization error\n",
    "    generalization_error_with_feature = test_error_with_feature - train_error_with_feature\n",
    "    generalization_error_without_feature = test_error_without_feature - train_error_without_feature\n",
    "\n",
    "    all_generalization_errors_with_feature.append(generalization_error_with_feature)\n",
    "    all_generalization_errors_without_feature.append(generalization_error_without_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00192232, 0.00365294, 0.00117994])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array(all_generalization_errors_with_feature)\n",
    "\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00093966,  0.00041431,  0.00107503])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = np.array(all_generalization_errors_without_feature)\n",
    "\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference\n",
    "diff = x2 - x1\n",
    "\n",
    "# Perform the one-sided t-test on the difference\n",
    "t_statistic, p_value = stats.ttest_1samp(diff, 0)\n",
    "\n",
    "# Since it's one-sided, we halve the p-value and change the sign of the t-statistic\n",
    "p_value /= 2\n",
    "t_statistic = -t_statistic if t_statistic < 0 else t_statistic\n",
    "\n",
    "# If your p_value is less than your alpha (commonly 0.05), \n",
    "# and your t_statistic is positive, you can reject the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08564267523749114"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0940494428365786"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
